#!/bin/bash

# –°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ —Å–∫—Ä–∞–ø–∏–Ω–≥ sitemap.xml

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"

cd "$PROJECT_DIR"

echo "üîç Starting data scraping from sitemap..."

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Go
if ! command -v go &> /dev/null; then
    echo "‚ùå Go is not installed. Please install Go first."
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
if [ $# -eq 0 ]; then
    echo "Usage: $0 <sitemap_url>"
    echo "Example: $0 https://example.com/sitemap.xml"
    exit 1
fi

SITEMAP_URL="$1"

echo "üì• Sitemap URL: $SITEMAP_URL"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Go –º–æ–¥—É–ª—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
if [ ! -f "go.sum" ]; then
    echo "üì¶ Installing Go dependencies..."
    go mod tidy
fi

# –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
if [ -d "data" ] && [ "$(ls -A data)" ]; then
    BACKUP_DIR="data_backup_$(date +%Y%m%d_%H%M%S)"
    echo "üíæ Creating backup: $BACKUP_DIR"
    cp -r data "$BACKUP_DIR"
fi

# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∞–ø–µ—Ä
echo "üöÄ Running scraper..."
go run scraper.go "$SITEMAP_URL"

# –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
if [ -d "data" ]; then
    FILE_COUNT=$(find data -name "*.md" | wc -l)
    echo "‚úÖ Scraping completed! Downloaded $FILE_COUNT files to data/ directory"
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤
    echo ""
    echo "üìÑ Sample files:"
    find data -name "*.md" | head -5 | while read file; do
        echo "  - $(basename "$file")"
    done
    
    if [ "$FILE_COUNT" -gt 5 ]; then
        echo "  ... and $((FILE_COUNT - 5)) more files"
    fi
else
    echo "‚ùå No data directory found after scraping"
    exit 1
fi

echo ""
echo "üéØ Next steps:"
echo "  1. Review the downloaded files in data/ directory"
echo "  2. Run ./scripts/import_data.sh to import into Manticore Search"
echo "  3. Test search with ./scripts/search_nl.sh \"your query\""